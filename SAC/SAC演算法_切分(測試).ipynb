{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 安裝"
      ],
      "metadata": {
        "id": "6LbfocGDBvmi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufaSy1loBMvQ",
        "outputId": "7e9bd223-3fa8-414b-999b-f44872cbc931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -ymnasium (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.43)\n",
            "Requirement already satisfied: ta in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.1.4)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ymnasium (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install yfinance ta\n",
        "!pip install gymnasium --upgrade\n",
        "!pip install stable-baselines3 --upgrade\n",
        "!pip install torch shimmy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 載入"
      ],
      "metadata": {
        "id": "Y-KFNIP3PAYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ta\n",
        "import stable_baselines3\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "import gymnasium as gym\n",
        "from gym import Env,spaces"
      ],
      "metadata": {
        "id": "cG5sq2XQPFYC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "a809db52-5291-49d2-ffb8-7aa0b172bbbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gymnasium.wrappers.monitoring'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d2b070eb8ad5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSAC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2c\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mA2C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_system_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mddpg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDDPG\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/a2c/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2c\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mA2C\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCnnPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMlpPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiInputPolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"CnnPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MlpPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultiInputPolicy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"A2C\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/a2c/a2c.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRolloutBuffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_policy_algorithm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOnPolicyAlgorithm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mActorCriticCnnPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActorCriticPolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBasePolicy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiInputActorCriticPolicy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/buffers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVecNormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_normalize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVecNormalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_transpose\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVecTransposeImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_video_recorder\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVecVideoRecorder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mVecEnvWrapperT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTypeVar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"VecEnvWrapperT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVecEnvWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/vec_video_recorder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgymnasium\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonitoring\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvideo_recorder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_vec_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVecEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVecEnvObs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVecEnvStepReturn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVecEnvWrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gymnasium.wrappers.monitoring'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 資料取得"
      ],
      "metadata": {
        "id": "YdwJ4HBVPI69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 股票代碼和期間\n",
        "tickers = ['META', 'AAPL', 'AMZN', 'MSFT', 'GOOG']\n",
        "start_date = '2010-01-01'\n",
        "end_date = '2020-12-31'\n",
        "\n",
        "# 下載股票數據\n",
        "data = yf.download(tickers, start=start_date, end=end_date)\n",
        "\n",
        "# 獲取 Adj Close、High、Low\n",
        "close_data = data['Adj Close']\n",
        "high_data = data['High']\n",
        "low_data = data['Low']\n",
        "\n",
        "# 計算每日收益率和對數收益率\n",
        "daily_return = close_data.pct_change()\n",
        "log_return = np.log(close_data / close_data.shift(1))\n",
        "\n",
        "# 每日收益率和對數收益率添加到 DataFrame 中\n",
        "close_data = pd.concat(\n",
        "    [close_data, daily_return.add_suffix('_Daily Return'), log_return.add_suffix('_Log Return')],\n",
        "    axis=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05MCqP3uPNMG",
        "outputId": "275b8c90-e1ef-4ab3-a699-14032d05d8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  5 of 5 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 設計變數\n"
      ],
      "metadata": {
        "id": "qp563Mb8Rv18"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 每支股票計算技術指標\n",
        "for ticker in tickers:\n",
        "    # 移動平均線 (50天窗口)\n",
        "    close_data[f'{ticker}_MA'] = close_data[ticker].rolling(window=50).mean()\n",
        "\n",
        "    # 相對強弱指數 (RSI, 14天窗口)\n",
        "    close_data[f'{ticker}_RSI'] = ta.momentum.RSIIndicator(close_data[ticker], window=14).rsi()\n",
        "\n",
        "    # 順勢指數 (CCI, 20天窗口)\n",
        "    close_data[f'{ticker}_CCI'] = ta.trend.CCIIndicator(high=high_data[ticker], low=low_data[ticker], close=close_data[ticker], window=20).cci()\n",
        "\n",
        "    # 平均趨向指數 (ADX)\n",
        "    close_data[f'{ticker}_ADX'] = ta.trend.ADXIndicator(high=high_data[ticker], low=low_data[ticker], close=close_data[ticker]).adx()\n",
        "\n",
        "    # 布林通道 (20天窗口)\n",
        "    bb = ta.volatility.BollingerBands(close_data[ticker], window=20)\n",
        "    close_data[f'{ticker}_BB High'] = bb.bollinger_hband()\n",
        "    close_data[f'{ticker}_BB Low'] = bb.bollinger_lband()\n",
        "\n",
        "    # MACD (標準窗口)\n",
        "    macd = ta.trend.MACD(close_data[ticker])\n",
        "    close_data[f'{ticker}_MACD'] = macd.macd()\n",
        "    close_data[f'{ticker}_MACD Signal'] = macd.macd_signal()\n",
        "\n",
        "# 協方差矩陣 (使用百分比變化计算協方差)\n",
        "cov_matrix = close_data[[ticker for ticker in tickers]].pct_change().cov()\n",
        "\n",
        "# 删除缺失值\n",
        "close_data = close_data.dropna()"
      ],
      "metadata": {
        "id": "obZLfT0OR4ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 切分資料集"
      ],
      "metadata": {
        "id": "Tng5o5jQS8K9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 80% 訓練集、20% 測試集\n",
        "#len(close_data) 總行數\n",
        "#int(...) 轉換為整數\n",
        "train_size = int(len(close_data) * 0.8)\n",
        "train_data = close_data.iloc[:train_size]\n",
        "test_data = close_data.iloc[train_size:]"
      ],
      "metadata": {
        "id": "_2xoMnbbS-6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 定義投資組合環境\n",
        "該環境模擬了一個簡單的投資組合管理過程，允許智能體在給定的市場數據下學習如何分配資產權重以最大化其投資reset回報step。計算獎勵。"
      ],
      "metadata": {
        "id": "oG9sfguyT7aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PortfolioEnv(gym.Env):\n",
        "    def __init__(self, data):#初始化\n",
        "        super(PortfolioEnv, self).__init__()\n",
        "        self.data = data\n",
        "        self.n_assets = len(tickers)\n",
        "        #規定安裝的操作空間，表示每個資產的投資比例，範圍從0到1\n",
        "        self.action_space = spaces.Box(low=0.0, high=1.0, shape=(self.n_assets,), dtype=np.float32)\n",
        "        #定義觀察空間，表示每個時間步驟的觀察內容，包括資產價格和投資組合權重\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(self.n_assets * 2,), dtype=np.float32)\n",
        "\n",
        "        self.start_index = 0\n",
        "        self.current_step = self.start_index\n",
        "        self.initial_balance = 1000000 #初始的資金餘額\n",
        "        self.balance = self.initial_balance\n",
        "        self.portfolio_weights = np.array([1 / self.n_assets] * self.n_assets)\n",
        "\n",
        "    def reset(self, seed=None, **kwargs):#重置環境(當前步數、餘額和投資組合權重)\n",
        "        self.current_step = self.start_index\n",
        "        self.balance = self.initial_balance\n",
        "        self.portfolio_weights = np.array([1 / self.n_assets] * self.n_assets)\n",
        "        return self.get_obs(), {}  #傳回觀察結果和一個空的資訊字典\n",
        "\n",
        "    def step(self, action):#行進方式\n",
        "        #標準化權重\n",
        "        action = action / np.sum(action)\n",
        "        self.portfolio_weights = action\n",
        "\n",
        "        #執行到最後一個資料，回傳觀察值、獎勵和結束標誌\n",
        "        if self.current_step >= len(self.data) - 1:\n",
        "            done = True\n",
        "            obs = self.get_obs()\n",
        "            return obs, 0, done, {}\n",
        "        #計算收益\n",
        "        returns = self.data.iloc[self.current_step + 1][tickers].pct_change().values\n",
        "        portfolio_return = np.dot(self.portfolio_weights, returns)\n",
        "        #計算獎勵並更新餘額\n",
        "        reward = self.balance * portfolio_return\n",
        "        self.balance += reward\n",
        "        #更新時間步數並判斷是否結束\n",
        "        self.current_step += 1\n",
        "        done = self.current_step >= len(self.data) - 1\n",
        "        #回傳觀察值、獎勵和結束標誌\n",
        "        obs = self.get_obs()\n",
        "        return obs, reward, done, {}\n",
        "\n",
        "    def get_obs(self):#獲取觀察值方法(收集當前時間步每個資產的價格、將目前的投資組合權重加到觀察值中)\n",
        "        obs = []\n",
        "        for ticker in tickers:\n",
        "            obs.append(self.data[ticker].iloc[self.current_step] if self.current_step < len(self.data) else 0)\n",
        "        obs.extend(self.portfolio_weights)\n",
        "        return np.array(obs)"
      ],
      "metadata": {
        "id": "xInESGU7T_JN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 創建訓練環境"
      ],
      "metadata": {
        "id": "wzrO7luQaRMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "\n",
        "# 創建訓練環境\n",
        "train_env = PortfolioEnv(train_data)\n",
        "# 監控環境(記錄智能體在每次（訓練輪次）中 reward、steps)\n",
        "train_env = Monitor(train_env)\n",
        "# 支持化環境\n",
        "# lambda: train_env每個函數傳回一個新的環境實例\n",
        "train_env = DummyVecEnv([lambda: train_env])"
      ],
      "metadata": {
        "id": "Qi0bqG4JaTm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 創建SAC模型、訓練模型"
      ],
      "metadata": {
        "id": "qlD69PK4bYs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#'MlpPolicy'是指使用一個梯度增長器（MLP）來選擇智能體在環境中每一步應該採取的行動\n",
        "model = SAC('MlpPolicy', env, verbose=1)\n",
        "# 訓練過程會進行 10,000 個時間\n",
        "model.learn(total_timesteps=10000)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7KNKNMUbuWX",
        "outputId": "42b63069-14c3-47cf-df63-d368a49cbe40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 42       |\n",
            "|    time_elapsed    | 18       |\n",
            "|    total_timesteps | 800      |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 25.3     |\n",
            "|    critic_loss     | 0.226    |\n",
            "|    ent_coef        | 0.813    |\n",
            "|    ent_coef_loss   | -0.325   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 699      |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 8        |\n",
            "|    fps             | 38       |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 1600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 51.6     |\n",
            "|    critic_loss     | 0.133    |\n",
            "|    ent_coef        | 0.647    |\n",
            "|    ent_coef_loss   | -0.61    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 1499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 12       |\n",
            "|    fps             | 37       |\n",
            "|    time_elapsed    | 64       |\n",
            "|    total_timesteps | 2400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 72.3     |\n",
            "|    critic_loss     | 0.265    |\n",
            "|    ent_coef        | 0.53     |\n",
            "|    ent_coef_loss   | -0.612   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 2299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 16       |\n",
            "|    fps             | 36       |\n",
            "|    time_elapsed    | 87       |\n",
            "|    total_timesteps | 3200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 85.5     |\n",
            "|    critic_loss     | 0.416    |\n",
            "|    ent_coef        | 0.456    |\n",
            "|    ent_coef_loss   | -0.499   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 36       |\n",
            "|    time_elapsed    | 109      |\n",
            "|    total_timesteps | 4000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 83.4     |\n",
            "|    critic_loss     | 0.618    |\n",
            "|    ent_coef        | 0.401    |\n",
            "|    ent_coef_loss   | -0.358   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 3899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 24       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 135      |\n",
            "|    total_timesteps | 4800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 81.2     |\n",
            "|    critic_loss     | 1.41     |\n",
            "|    ent_coef        | 0.345    |\n",
            "|    ent_coef_loss   | -0.464   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 4699     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 28       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 157      |\n",
            "|    total_timesteps | 5600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 90.3     |\n",
            "|    critic_loss     | 1.21     |\n",
            "|    ent_coef        | 0.288    |\n",
            "|    ent_coef_loss   | -0.483   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5499     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 32       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 179      |\n",
            "|    total_timesteps | 6400     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 82       |\n",
            "|    critic_loss     | 1.89     |\n",
            "|    ent_coef        | 0.241    |\n",
            "|    ent_coef_loss   | -0.446   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6299     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 36       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 201      |\n",
            "|    total_timesteps | 7200     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 68.3     |\n",
            "|    critic_loss     | 1.53     |\n",
            "|    ent_coef        | 0.205    |\n",
            "|    ent_coef_loss   | -0.351   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7099     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 224      |\n",
            "|    total_timesteps | 8000     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 68.2     |\n",
            "|    critic_loss     | 2.7      |\n",
            "|    ent_coef        | 0.176    |\n",
            "|    ent_coef_loss   | -0.41    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 7899     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 44       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 246      |\n",
            "|    total_timesteps | 8800     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 65.3     |\n",
            "|    critic_loss     | 4.84     |\n",
            "|    ent_coef        | 0.153    |\n",
            "|    ent_coef_loss   | -0.273   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8699     |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 48       |\n",
            "|    fps             | 35       |\n",
            "|    time_elapsed    | 269      |\n",
            "|    total_timesteps | 9600     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | 72.8     |\n",
            "|    critic_loss     | 2.53     |\n",
            "|    ent_coef        | 0.127    |\n",
            "|    ent_coef_loss   | -0.197   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9499     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.sac.sac.SAC at 0x7c3f68a0f310>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 建立測試環境"
      ],
      "metadata": {
        "id": "55i1YbAonYlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_env = Monitor(PortfolioEnv(test_data))\n",
        "test_env = DummyVecEnv([lambda: test_env])"
      ],
      "metadata": {
        "id": "JIQn4PuWnfN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 評估模型"
      ],
      "metadata": {
        "id": "4A_FNkONniTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_rewards = 0\n",
        "\n",
        "#循環進行預測與環境步進\n",
        "for _ in range(len(test_data) - 1):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, reward, done, _ = test_env.step(action)\n",
        "    total_rewards += reward\n",
        "    if done:\n",
        "        break\n",
        "\n",
        "print(f'Total Rewards: {total_rewards}')\n",
        "print(f'Final Balance: {underlying_env.balance}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbbniWYRnqnk",
        "outputId": "4eaba1dd-b0de-4580-844b-64f4a0b96d83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Rewards: 0\n",
            "Final Balance: 1000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#結果探討\n",
        "**超參數調整**\n",
        "軟性演員評論家演算法 (SAC)\n",
        "Reward Scale 是 SAC 特有的超參數,該參數意涵是指直接讓獎勵(Reward) 乘以一個常數(Reward Scale,k),在不破壞獎勵函數的前提下調整獎勵值,從而間接調整 Q 值到合適的水準,∑kri = k∑ri =kQt,\n",
        "其中 Q 為累積收益,本文使用 k 為 1000,該數字是依經驗進行調整的適當水準,原論文已有論述僅需讓累計收益的範圍落在正負 1000以內即可,不需要精細調整\n",
        "\n",
        "儘管如此它仍為本模型最關鍵的超參數,該參數越大隱含更少的 Entropy,將使得 SAC 模型漸近於 DDPG,該參數越小,將使的策略分布趨近於 Uniform,代表此將不利於探索。\n",
        "\n",
        "**變數調整**\n",
        "本身該資料集報酬為負，導致無法決策且有效學習。\n",
        "\n",
        "\n",
        "\n",
        "1.模型未訓練充分：\n",
        "訓練次數（total_timesteps）可能使模型學習達到有效的策略。\n",
        "\n",
        "試著增加total_timesteps數值，讓模型有更多的時間學習有效的策略。\n",
        "\n",
        "2.模型複雜度：\n",
        "MLP（多層採集器）的結構可能不夠複雜，無法捕捉資料中的潛在模式。\n",
        "\n",
        "考慮增加MLP的層數或每層的神經元數量，以提高模型的表達能力。\n",
        "\n",
        "3.測試資料特性：\n",
        "資料可能與訓練資料差異增大，導致模型在未見過的測試情況下表現不佳。\n",
        "\n",
        "在測試模型之前，先在訓練資料上進行調試，確保模型能夠在訓練資料中獲得合理的獎勵。\n",
        "\n",
        "改進方法\n",
        "增加訓練時間：\n",
        "\n",
        "試著增加total_timesteps數值，讓模型有更多的時間學習有效的策略。\n",
        "調整獎勵機制：\n",
        "\n",
        "重新設計獎勵結構，考慮引入更多的獎勵訊號，例如交易的成功率、波動率等，以便模型能學會平衡風險與效益。\n",
        "查詢資料品質：\n",
        "\n",
        "輸入的資料沒有缺失值或異常值，並且具有足夠的時間跨度和多樣性，確保模型能夠學習。\n",
        "優化模型結構：\n",
        "\n",
        "考慮增加MLP的層數或每層的神經元數量，以提高模型的表達能力。\n",
        "調整動作空間：\n",
        "\n",
        "重新安排行動歸一化的流程，確保模型能夠探索有效的投資組合。\n",
        "使用訓練資料進行調試：\n",
        "\n",
        "在測試模型之前，先在訓練資料上進行調試，確保模型能夠在訓練資料中獲得合理的獎勵。\n",
        "增加探索性：\n",
        "\n",
        "調整演算法的超參數，例如增加探索率，以便模型能夠嘗試不同的投資策略。"
      ],
      "metadata": {
        "id": "i6i5XiQdob9T"
      }
    }
  ]
}